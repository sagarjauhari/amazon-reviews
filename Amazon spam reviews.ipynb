{
 "metadata": {
  "name": "Amazon spam reviews"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Text mining on Amazon Reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import csv\n",
      "from datetime import date\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Connect to the database for test data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Connect to the MySQL Database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import MySQLdb\n",
      "db = MySQLdb.connect(host=\"localhost\",\n",
      "                     user=\"root\",\n",
      "                      passwd=\"\",\n",
      "                      db=\"amazon\")\n",
      "cur = db.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Execute test query"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur.execute(\"SELECT * from review limit 1\");\n",
      "for row in cur.fetchall():\n",
      "    print row[8]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "str = \"R000000000000X One of Tribe's best and also one of the most unheard of. Some of their greatest tracks except for the sellout stressed out - which inspired the industry to labelthem as anything but real\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Read the training data and build model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fraud_reviews = []\n",
      "genuine_reviews = []\n",
      "reviews = []\n",
      "\n",
      "with open('/home/sagar/Dropbox/Academics/nc_SDM/project/op_spam_v1.3/data/fraud.csv','rb') as csvfile:\n",
      "    csvreader = csv.reader(csvfile, delimiter=';',quotechar='|')\n",
      "    for row in csvreader:\n",
      "        fraud_reviews.append((row[0],row[1]))\n",
      "\n",
      "with open('/home/sagar/Dropbox/Academics/nc_SDM/project/op_spam_v1.3/data/genuine.csv','rb') as csvfile:\n",
      "    csvreader = csv.reader(csvfile, delimiter=';',quotechar='|')\n",
      "    for row in csvreader:\n",
      "        genuine_reviews.append((row[0],row[1]))\n",
      "\n",
      "for(words, label) in fraud_reviews + genuine_reviews:\n",
      "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
      "    reviews.append((words_filtered,label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Build Classifier\n",
      "Extract list of words ordered by frequency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_word_features(wordlist):\n",
      "    wordlist = nltk.FreqDist(wordlist)\n",
      "    word_features = wordlist.keys()\n",
      "    return word_features, wordlist\n",
      "    \n",
      "def get_words_in_reviews(reviews):\n",
      "    all_words = []\n",
      "    for(words,labels) in reviews:\n",
      "        all_words.extend(words)\n",
      "    return all_words\n",
      "\n",
      "word_features,wordlist = get_word_features(get_words_in_reviews(reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_features(document):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_features:\n",
      "        features['contains(%s)' % word] = (word in document_words)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With our feature extractor, we can apply the features to our classifier using the method apply_features. We pass the feature extractor along with the review list defined above. The variable \u2018training_set\u2019 contains the labeled feature sets. It is a list of tuples which each tuple containing the feature dictionary and the sentiment string for each tweet. The sentiment string is also called \u2018label\u2019."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_set = nltk.classify.apply_features(extract_features, reviews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train the *Naive Bayes* classifier. (This will take some time)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time classifier = nltk.NaiveBayesClassifier.train(training_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 24.13 s, sys: 0.03 s, total: 24.16 s\n",
        "Wall time: 27.19 s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Analyse the classifier\n",
      "Finding out the most informative features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classifier.show_most_informative_features(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most Informative Features\n",
        "         contains(block) = True           genuin : fraud  =     15.7 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        contains(indoor) = True            fraud : genuin =     15.0 : 1.0\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fraud_predicted = []\n",
      "for review in reviews:\n",
      "    #print review[0];\n",
      "    res = classifier.prob_classify(extract_features(review[0]))\n",
      "    fraud_predicted.append(res.prob('fraud'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=[]\n",
      "y=[]\n",
      "for num in range(100,1000):\n",
      "    tp = 0\n",
      "    fp = 0\n",
      "    tn = 0\n",
      "    fn = 0\n",
      "    limit = num/1000.0\n",
      "    for i in range(0,800):\n",
      "        if reviews[i][1]=='fraud' and fraud_predicted[i]>=limit:\n",
      "            tp = tp + 1\n",
      "        elif reviews[i][1]=='fraud' and fraud_predicted[i]<limit:\n",
      "            fn = fn + 1\n",
      "        elif reviews[i][1]!='fraud' and fraud_predicted[i]>=limit:\n",
      "            fp = fp + 1\n",
      "        else:\n",
      "            tn = tn + 1\n",
      "    \n",
      "    accuracy = (tp + tn)/(800.0)\n",
      "    x.append(limit)\n",
      "    y.append(accuracy)\n",
      "\n",
      "plt.plot(x, y, '--')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Use the classifier to classify reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur.execute(\"SELECT * from review limit 1\");\n",
      "for row in cur.fetchall():\n",
      "    review = row[8]\n",
      "    res = classifier.prob_classify(extract_features(review.split()))\n",
      "    print res.prob('fraud')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.992415521806\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writer = csv.writer(open(\"/media/media/DATA/amazon_dump/naive_bayes/ans.csv\",'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "mysql> select count(*) from review where Product_id in (select Product_id from product where P_class=' Books');\n",
      "+----------+\n",
      "| count(*) |\n",
      "+----------+\n",
      "|  1847405 |\n",
      "+----------+"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Option 2\n",
      "1. Append to same file.\n",
      "2. increase confidence for naive bayes classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/ans_71001.csv\",'w') as myfile:\n",
      "    writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
      "    cur.execute(\"select * from review where Product_id in (select Product_id from product where P_class=' Books') limit \"+ str(size) +\" offset \" + str(offset*size));\n",
      "    for row in cur.fetchall():\n",
      "        review = row[8]\n",
      "        review_id = row[0]\n",
      "        reviewer_id = row[2]\n",
      "        writer.writerow( [review_id, reviewer_id, classifier.classify(extract_features(review.split()))])\n",
      "    myfile.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Option 3\n",
      "Find review results only for Book.xx.user.txt files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total = 1472830;\n",
      "size = 10000;\n",
      "\n",
      "with open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/ans_book_80_user_452506_onwards.csv\",'a') as myfile:\n",
      "    writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
      "    for line in open(\"/home/sagar/Dropbox/Academics/nc_SDM/project/book_80_2662user_onwards.txt\").xreadlines():\n",
      "        id = line.rstrip()\n",
      "        cur.execute(\"select Review_id, Reviewer_id, Texts,Product_id FROM review where Reviewer_id='\"+id+\"'\");\n",
      "        for row in cur.fetchall():\n",
      "            review_id = row[0]\n",
      "            reviewer_id = row[1]\n",
      "            review = row[2]\n",
      "            product_id = row[3]\n",
      "            writer.writerow( [product_id,review_id, reviewer_id, classifier.classify(extract_features(review.split()))])\n",
      "        myfile.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Option 4\n",
      "Also outptut the probability of fraudness"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur.execute(\"select Review_id, Reviewer_id, Texts,Product_id FROM review where Reviewer_id='A3TGV2A95WOLEB'\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/ans_10_minus_80_2nd_half.csv\",'a') as myfile:\n",
      "    writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
      "    for line in open(\"/home/sagar/Dropbox/Academics/nc_SDM/project/10_minus_80_2nd_half.txt\").xreadlines():\n",
      "        id = line.rstrip()\n",
      "        cur.execute(\"select Review_id, Reviewer_id, Texts,Product_id FROM review where Reviewer_id='\"+id+\"'\");\n",
      "        for row in cur.fetchall():\n",
      "            review_id = row[0]\n",
      "            reviewer_id = row[1]\n",
      "            review = row[2]\n",
      "            product_id = row[3]\n",
      "            prob = classifier.prob_classify(extract_features(review.split())).prob('fraud')\n",
      "            writer.writerow( [product_id,review_id, reviewer_id, '{0:.8f}'.format(round(prob,8))])\n",
      "        myfile.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/sports_n_outdoors_70400.csv\",'a') as myfile:\n",
      "    writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
      "    total=122327\n",
      "    size=100\n",
      "    for i in range(0,total/size):\n",
      "        cur.execute(\"select Review_id, Reviewer_id, Texts,Product_id FROM review where Product_id in (select Product_id from product where P_class=' Sports &amp; Outdoors')  limit \" + str(size) + \" offset \" + str(size*(i)));\n",
      "        for row in cur.fetchall():\n",
      "            review_id = row[0]\n",
      "            reviewer_id = row[1]\n",
      "            review = row[2]\n",
      "            product_id = row[3]\n",
      "            prob = classifier.prob_classify(extract_features(review.split())).prob('fraud')\n",
      "            writer.writerow( [product_id,review_id, reviewer_id, '{0:.8f}'.format(round(prob,8))])\n",
      "        myfile.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Preparation for rules 1,2,3,5 (AW, MNR, RC, RL)\n",
      "As opinion spamming involves writing\n",
      "fake experiences, there is probably not much to write or at least a\n",
      "(paid) spammer probably does not want to invest too much time in\n",
      "writing. We show the CDF of the average number of words per\n",
      "review for all reviewers in Figure 3(e). We see that a majority (\u2248\n",
      "80%) of spammers are bounded by 135 words in average review\n",
      "length which is quite short as compared to non-spammers where\n",
      "we find only 8% are bounded by 200 words while a majority\n",
      "(92%) have higher average review word length (> 200)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out_file=\"/media/media/DATA/amazon_dump/naive_bayes_1file/sports_rule_r1235_prep.csv\"\n",
      "prod_id_file=\"/home/sagar/Dropbox/Academics/nc_SDM/project/sport_outdoort.csv\"\n",
      "\n",
      "with open(out_file,'a') as myfile:\n",
      "    writer = csv.writer(myfile, delimiter=',', quotechar='\"')\n",
      "    for line in open(prod_id_file).xreadlines():\n",
      "        id = line.rstrip()\n",
      "        cur.execute(\"select Review_id, Reviewer_id, Texts, Product_id, time FROM review where Product_id='\"+id+\"'\");\n",
      "        for row in cur.fetchall():\n",
      "            review_id = row[0]\n",
      "            reviewer_id = row[1]\n",
      "            review = row[2]\n",
      "            product_id = row[3]\n",
      "            rev_time = row[4]\n",
      "            length = len(review.split())\n",
      "            writer.writerow( [reviewer_id, rev_time, length])\n",
      "        myfile.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Read data from created file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If the file above is created successfully, then parse the file\n",
      "input_file = csv.reader(open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/sports_rule_r1235_prep.csv\", 'rb'))\n",
      "reviewers = {}\n",
      "for row in input_file:\n",
      "    r = row[0]\n",
      "    rev_time = time.strptime(row[1],\"%B %d, %Y\")\n",
      "    rev_date = date(rev_time.tm_year, rev_time.tm_mon, rev_time.tm_mday)\n",
      "    word_count=row[2]\n",
      "    if reviewers.__contains__(r):\n",
      "        if reviewers[r]['min'] > rev_date:\n",
      "            reviewers[r]['min'] = rev_date\n",
      "        if reviewers[r]['max'] < rev_date:\n",
      "            reviewers[r]['max'] = rev_date\n",
      "    else:\n",
      "        reviewers[r]={}\n",
      "        reviewers[r]['min']=rev_date\n",
      "        reviewers[r]['max']=rev_date\n",
      "\n",
      "r1_file = csv.writer(open(\"/media/media/DATA/amazon_dump/naive_bayes_1file/sports_rule_r1.csv\", 'wb'))\n",
      "for key, value in mydict.items():\n",
      "    r1_file.writerow([key, value['max']-value['min']])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "<module 'time' (built-in)>"
       ]
      }
     ],
     "prompt_number": 40
    }
   ],
   "metadata": {}
  }
 ]
}